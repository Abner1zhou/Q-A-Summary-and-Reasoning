{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework-week2\n",
    "\n",
    "1. 通过gensim训练词向量\n",
    "\n",
    "1.1 利用分词后的项目数据生成训练词向量用的训练数据\n",
    "\n",
    "1.2 保存词向量训练数据\n",
    "\n",
    "1.3 应用gensim中Word2Vec或Fasttext训练词向量\n",
    "\n",
    "1.4 保存训练好的词向量\n",
    "\n",
    "2. 构建embedding_matrix\n",
    "\n",
    "读取上步计算词向量和构建的vocab词表，以vocab中的index为key值构建embedding_matrix\n",
    "\n",
    "eg: embedding_matrix[i] = [embedding_vector]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经在02_get_w2v.py里完成了work2vec的模型制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.config import *\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/home/abner/PycharmProjects/NLP_Pro_01/database/merged_train_test_seg_data.csv\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(merger_seg_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 导入已经制作好的w2v模板\n",
    "model = word2vec.Word2Vec.load(w2v_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建embedding_matrix\n",
    "embedding_matrix 是word2vec模型里面第二层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = {word:index for index, word in enumerate(model.wv.index2word)}\n",
    "reverse_vocab = {index: word for index, word in enumerate(model.wv.index2word)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding_matrix_path='database/embedding_matrix.txt'\n",
    "\n",
    "def get_embedding_matrix(wv_model):\n",
    "    # 获取vocab大小\n",
    "    vocab_size = len(wv_model.wv.vocab)\n",
    "    # 获取embedding维度\n",
    "    embedding_dim = wv_model.wv.vector_size\n",
    "    print('vocab_size, embedding_dim:', vocab_size, embedding_dim)\n",
    "    # 初始化矩阵\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    # 按顺序填充\n",
    "    for i in range(vocab_size):\n",
    "        embedding_matrix[i, :] = wv_model.wv[wv_model.wv.index2word[i]]\n",
    "        embedding_matrix = embedding_matrix.astype('float32')\n",
    "    # 断言检查维度是否符合要求\n",
    "    assert embedding_matrix.shape == (vocab_size, embedding_dim)\n",
    "    # 保存矩阵\n",
    "    np.savetxt(save_embedding_matrix_path, embedding_matrix, fmt='%0.8f')\n",
    "    print('embedding matrix extracted')\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size, embedding_dim: 32993 200\n",
      "embedding matrix extracted\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = get_embedding_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.wv['问题']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法二，使用word2vec内置函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_wv=model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix == embedding_matrix_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nlp_pro_01",
   "language": "python",
   "display_name": "NLP_Pro_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}