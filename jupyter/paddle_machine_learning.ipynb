{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import six\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.layers as layers\n",
    "\n",
    "dict_size = 30000  # 词典大小\n",
    "bos_id = 0  # 词典中start token对应的id\n",
    "eos_id = 1  # 词典中end token对应的id\n",
    "source_dict_size = target_dict_size = dict_size  # 源/目标语言字典大小\n",
    "word_dim = 512  # 词向量维度\n",
    "hidden_dim = 512  # 编码器中的隐层大小\n",
    "decoder_size = hidden_dim  # 解码器中的隐层大小\n",
    "max_length = 256  # 解码生成句子的最大长度\n",
    "beam_size = 4  # beam search的柱宽度\n",
    "batch_size = 64  # batch 中的样本数\n",
    "\n",
    "model_save_dir = \"machine_translation.inference.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_func(is_train=True):\n",
    "    # 源语言source数据\n",
    "    src = fluid.data(name=\"src\", shape=[None, None], dtype=\"int64\")\n",
    "    src_sequence_length = fluid.data(name=\"src_sequence_length\",\n",
    "                                     shape=[None],\n",
    "                                     dtype=\"int64\")\n",
    "    inputs = [src, src_sequence_length]\n",
    "    # 训练时还需要目标语言target和label数据\n",
    "    if is_train:\n",
    "        trg = fluid.data(name=\"trg\", shape=[None, None], dtype=\"int64\")\n",
    "        trg_sequence_length = fluid.data(name=\"trg_sequence_length\",\n",
    "                                        shape=[None],\n",
    "                                        dtype=\"int64\")\n",
    "        label = fluid.data(name=\"label\", shape=[None, None], dtype=\"int64\")\n",
    "        inputs += [trg, trg_sequence_length, label]\n",
    "    # data loader\n",
    "    loader = fluid.io.DataLoader.from_generator(feed_list=inputs,\n",
    "                                                capacity=10,\n",
    "                                                iterable=True,\n",
    "                                                use_double_buffer=True)\n",
    "    return inputs, loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(src_embedding, src_sequence_length):\n",
    "    # 使用GRUCell构建前向RNN\n",
    "    encoder_fwd_cell = layers.GRUCell(hidden_size=hidden_dim)\n",
    "    encoder_fwd_output, fwd_state = layers.rnn(\n",
    "        cell=encoder_fwd_cell,\n",
    "        inputs=src_embedding,\n",
    "        sequence_length=src_sequence_length,\n",
    "        time_major=False,\n",
    "        is_reverse=False)\n",
    "    # 使用GRUCell构建反向RNN\n",
    "    encoder_bwd_cell = layers.GRUCell(hidden_size=hidden_dim)\n",
    "    encoder_bwd_output, bwd_state = layers.rnn(\n",
    "        cell=encoder_bwd_cell,\n",
    "        inputs=src_embedding,\n",
    "        sequence_length=src_sequence_length,\n",
    "        time_major=False,\n",
    "        is_reverse=True)\n",
    "    # 拼接前向与反向GRU的编码结果得到h\n",
    "    encoder_output = layers.concat(\n",
    "        input=[encoder_fwd_output, encoder_bwd_output], axis=2)\n",
    "    encoder_state = layers.concat(input=[fwd_state, bwd_state], axis=1)\n",
    "    return encoder_output, encoder_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderCell(layers.RNNCell):\n",
    "    def __init__(self, hidden_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru_cell = layers.GRUCell(hidden_size)\n",
    "\n",
    "    def attention(self, hidden, encoder_output, encoder_output_proj,\n",
    "                  encoder_padding_mask):\n",
    "        # 定义attention用以计算context，即 c_i，这里使用Bahdanau attention机制\n",
    "        decoder_state_proj = layers.unsqueeze(\n",
    "            layers.fc(hidden, size=self.hidden_size, bias_attr=False), [1])\n",
    "        mixed_state = fluid.layers.elementwise_add(\n",
    "            encoder_output_proj,\n",
    "            layers.expand(decoder_state_proj,\n",
    "                        [1, layers.shape(decoder_state_proj)[1], 1]))\n",
    "        attn_scores = layers.squeeze(\n",
    "            layers.fc(input=mixed_state,\n",
    "                    size=1,\n",
    "                    num_flatten_dims=2,\n",
    "                    bias_attr=False), [2])\n",
    "        if encoder_padding_mask is not None:\n",
    "            attn_scores = layers.elementwise_add(attn_scores,\n",
    "                                                encoder_padding_mask)\n",
    "        attn_scores = layers.softmax(attn_scores)\n",
    "        context = layers.reduce_sum(layers.elementwise_mul(encoder_output,\n",
    "                                                        attn_scores,\n",
    "                                                        axis=0),\n",
    "                                    dim=1)\n",
    "        return context\n",
    "\n",
    "    def call(self,\n",
    "             step_input,\n",
    "             hidden,\n",
    "             encoder_output,\n",
    "             encoder_output_proj,\n",
    "             encoder_padding_mask=None):\n",
    "        # Bahdanau attention\n",
    "        context = self.attention(hidden, encoder_output, encoder_output_proj,\n",
    "                                encoder_padding_mask)\n",
    "        step_input = layers.concat([step_input, context], axis=1)\n",
    "        # GRU\n",
    "        output, new_hidden = self.gru_cell(step_input, hidden)\n",
    "        return output, new_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(encoder_output,\n",
    "            encoder_output_proj,\n",
    "            encoder_state,\n",
    "            encoder_padding_mask,\n",
    "            trg=None,\n",
    "            is_train=True):\n",
    "    # 定义 RNN 所需要的组件\n",
    "    decoder_cell = DecoderCell(hidden_size=decoder_size)\n",
    "    decoder_initial_states = layers.fc(encoder_state,\n",
    "                                    size=decoder_size,\n",
    "                                    act=\"tanh\")\n",
    "    trg_embeder = lambda x: fluid.embedding(input=x,\n",
    "                                            size=[target_dict_size, hidden_dim],\n",
    "                                            dtype=\"float32\",\n",
    "                                            param_attr=fluid.ParamAttr(\n",
    "                                                name=\"trg_emb_table\"))\n",
    "    output_layer = lambda x: layers.fc(x,\n",
    "                                       size=target_dict_size,\n",
    "                                       num_flatten_dims=len(x.shape) - 1,\n",
    "                                       param_attr=fluid.ParamAttr(name=\n",
    "                                                                  \"output_w\"))\n",
    "    if is_train:  # 训练\n",
    "        # 训练时使用 `layers.rnn` 构造由 `cell` 指定的循环神经网络\n",
    "        # 循环的每一步从 `inputs` 中切片产生输入，并执行 `cell.call`\n",
    "        decoder_output, _ = layers.rnn(\n",
    "            cell=decoder_cell,\n",
    "            inputs=trg_embeder(trg),\n",
    "            initial_states=decoder_initial_states,\n",
    "            time_major=False,\n",
    "            encoder_output=encoder_output,\n",
    "            encoder_output_proj=encoder_output_proj,\n",
    "            encoder_padding_mask=encoder_padding_mask)\n",
    "        decoder_output = output_layer(decoder_output)\n",
    "    else:  # 基于 beam search 的预测生成\n",
    "        # beam search 时需要将用到的形为 `[batch_size, ...]` 的张量扩展为 `[batch_size* beam_size, ...]`\n",
    "        encoder_output = layers.BeamSearchDecoder.tile_beam_merge_with_batch(\n",
    "            encoder_output, beam_size)\n",
    "        encoder_output_proj = layers.BeamSearchDecoder.tile_beam_merge_with_batch(\n",
    "            encoder_output_proj, beam_size)\n",
    "        encoder_padding_mask = layers.BeamSearchDecoder.tile_beam_merge_with_batch(\n",
    "            encoder_padding_mask, beam_size)\n",
    "        # BeamSearchDecoder 定义了单步解码的操作：`cell.call` + `beam_search_step`\n",
    "        beam_search_decoder = layers.BeamSearchDecoder(cell=decoder_cell,\n",
    "                                                       start_token=bos_id,\n",
    "                                                       end_token=eos_id,\n",
    "                                                       beam_size=beam_size,\n",
    "                                                       embedding_fn=trg_embeder,\n",
    "                                                       output_fn=output_layer)\n",
    "        # 使用 layers.dynamic_decode 动态解码\n",
    "        # 重复执行 `decoder.step()` 直到其返回的表示完成状态的张量中的值全部为True或解码步骤达到 `max_step_num`\n",
    "        decoder_output, _ = layers.dynamic_decode(\n",
    "            decoder=beam_search_decoder,\n",
    "            inits=decoder_initial_states,\n",
    "            max_step_num=max_length,\n",
    "            output_time_major=False,\n",
    "            encoder_output=encoder_output,\n",
    "            encoder_output_proj=encoder_output_proj,\n",
    "            encoder_padding_mask=encoder_padding_mask)\n",
    "\n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func(inputs, is_train=True):\n",
    "    # 源语言输入\n",
    "    src = inputs[0]\n",
    "    src_sequence_length = inputs[1]\n",
    "    src_embeder = lambda x: fluid.embedding(\n",
    "        input=x,\n",
    "        size=[source_dict_size, hidden_dim],\n",
    "        dtype=\"float32\",\n",
    "        param_attr=fluid.ParamAttr(name=\"src_emb_table\"))\n",
    "    src_embedding = src_embeder(src)\n",
    "\n",
    "    # 编码器\n",
    "    encoder_output, encoder_state = encoder(src_embedding, src_sequence_length)\n",
    "\n",
    "    encoder_output_proj = layers.fc(input=encoder_output,\n",
    "                                    size=decoder_size,\n",
    "                                    num_flatten_dims=2,\n",
    "                                    bias_attr=False)\n",
    "    src_mask = layers.sequence_mask(src_sequence_length,\n",
    "                                    maxlen=layers.shape(src)[1],\n",
    "                                    dtype=\"float32\")\n",
    "    encoder_padding_mask = (src_mask - 1.0) * 1e9\n",
    "\n",
    "    # 目标语言输入，训练时有、预测生成时无该输入\n",
    "    trg = inputs[2] if is_train else None\n",
    "\n",
    "    # 解码器\n",
    "    output = decoder(encoder_output=encoder_output,\n",
    "                     encoder_output_proj=encoder_output_proj,\n",
    "                     encoder_state=encoder_state,\n",
    "                     encoder_padding_mask=encoder_padding_mask,\n",
    "                     trg=trg,\n",
    "                     is_train=is_train)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits, label, trg_sequence_length):\n",
    "    probs = layers.softmax(logits)\n",
    "    # 使用交叉熵损失函数\n",
    "    loss = layers.cross_entropy(input=probs, label=label)\n",
    "    # 根据长度生成掩码，并依此剔除 padding 部分计算的损失\n",
    "    trg_mask = layers.sequence_mask(trg_sequence_length,\n",
    "                                    maxlen=layers.shape(logits)[1],\n",
    "                                    dtype=\"float32\")\n",
    "    avg_cost = layers.reduce_sum(loss * trg_mask) / layers.reduce_sum(trg_mask)\n",
    "    return avg_cost\n",
    "\n",
    "def optimizer_func():\n",
    "    # 设置梯度裁剪\n",
    "    fluid.clip.set_gradient_clip(\n",
    "        clip=fluid.clip.GradientClipByGlobalNorm(clip_norm=5.0))\n",
    "    # 定义先增后降的学习率策略\n",
    "    lr_decay = fluid.layers.learning_rate_scheduler.noam_decay(hidden_dim, 1000)\n",
    "    return fluid.optimizer.Adam(\n",
    "        learning_rate=lr_decay,\n",
    "        regularization=fluid.regularizer.L2DecayRegularizer(\n",
    "            regularization_coeff=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_generator(batch_size, pad_id, is_train=True):\n",
    "    data_generator = fluid.io.shuffle(\n",
    "        paddle.dataset.wmt16.train(source_dict_size, target_dict_size),\n",
    "        buf_size=10000) if is_train else paddle.dataset.wmt16.test(\n",
    "            source_dict_size, target_dict_size)\n",
    "    batch_generator = fluid.io.batch(data_generator, batch_size=batch_size)\n",
    "\n",
    "    # 对 batch 内的数据进行 padding\n",
    "    def _pad_batch_data(insts, pad_id):\n",
    "        seq_lengths = np.array(list(map(len, insts)), dtype=\"int64\")\n",
    "        max_len = max(seq_lengths)\n",
    "        pad_data = np.array(\n",
    "            [inst + [pad_id] * (max_len - len(inst)) for inst in insts],\n",
    "            dtype=\"int64\")\n",
    "        return pad_data, seq_lengths\n",
    "\n",
    "    def _generator():\n",
    "        for batch in batch_generator():\n",
    "            batch_src = [ins[0] for ins in batch]\n",
    "            src_data, src_lengths = _pad_batch_data(batch_src, pad_id)\n",
    "            inputs = [src_data, src_lengths]\n",
    "            if is_train:  #训练时包含 target 和 label 数据\n",
    "                batch_trg = [ins[1] for ins in batch]\n",
    "                trg_data, trg_lengths = _pad_batch_data(batch_trg, pad_id)\n",
    "                batch_lbl = [ins[2] for ins in batch]\n",
    "                lbl_data, _ = _pad_batch_data(batch_lbl, pad_id)\n",
    "                inputs += [trg_data, trg_lengths, lbl_data]\n",
    "            yield inputs\n",
    "\n",
    "    return _generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prog = fluid.Program()\n",
    "startup_prog = fluid.Program()\n",
    "with fluid.program_guard(train_prog, startup_prog):\n",
    "    with fluid.unique_name.guard():\n",
    "        # 训练时：\n",
    "        # inputs = [src, src_sequence_length, trg, trg_sequence_length, label]\n",
    "        inputs, loader = data_func(is_train=True)\n",
    "        logits = model_func(inputs, is_train=True)\n",
    "        loss = loss_func(logits, inputs[-1], inputs[-2])\n",
    "        optimizer = optimizer_func()\n",
    "        optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=/usr/local/cuda/lib64/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\n2   paddle::platform::dynload::GetCublasDsoHandle()\n3   void std::__once_call_impl<std::_Bind_simple<paddle::platform::dynload::DynLoad__cublasCreate_v2::operator()<cublasContext**>(cublasContext**)::{lambda()#1} ()> >()\n4   paddle::platform::CublasHandleHolder::CublasHandleHolder(CUstream_st*, cublasMath_t)\n5   paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace)\n6   std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&)\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\n9   std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred()\n10  paddle::platform::DeviceContextPool::Get(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\n11  paddle::framework::GarbageCollector::GarbageCollector(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n12  paddle::framework::UnsafeFastGPUGarbageCollector::UnsafeFastGPUGarbageCollector(paddle::platform::CUDAPlace const&, unsigned long)\n13  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\n14  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\n\n----------------------\nError Message Summary:\n----------------------\nPaddleCheckError: Failed to find dynamic library: libcublas.so ( libcublas.so: cannot open shared object file: No such file or directory ) \n Please specify its path correctly using following ways: \n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \n For instance, issue command: export LD_LIBRARY_PATH=... \n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-53c2a539e90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 定义执行器，初始化参数并绑定Program\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartup_prog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m prog = fluid.CompiledProgram(train_prog).with_data_parallel(\n\u001b[1;32m     13\u001b[0m     loss_name=loss.name)\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    773\u001b[0m                 warnings.warn(\n\u001b[1;32m    774\u001b[0m                     \"The following exception is not an EOF exception.\")\n\u001b[0;32m--> 775\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     def _run_impl(self, program, feed, fetch_list, feed_var_name,\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    768\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                 use_program_cache=use_program_cache)\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEOFException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_impl\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0mreturn_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_numpy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m                 use_program_cache=use_program_cache)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mprogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/executor.py\u001b[0m in \u001b[0;36m_run_program\u001b[0;34m(self, program, feed, fetch_list, feed_var_name, fetch_var_name, scope, return_numpy, use_program_cache)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_program_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             self._default_executor.run(program.desc, scope, 0, True, True,\n\u001b[0;32m--> 894\u001b[0;31m                                        fetch_var_name)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             self._default_executor.run_cached_prepared_ctx(ctx, scope, False,\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\n2   paddle::platform::dynload::GetCublasDsoHandle()\n3   void std::__once_call_impl<std::_Bind_simple<paddle::platform::dynload::DynLoad__cublasCreate_v2::operator()<cublasContext**>(cublasContext**)::{lambda()#1} ()> >()\n4   paddle::platform::CublasHandleHolder::CublasHandleHolder(CUstream_st*, cublasMath_t)\n5   paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace)\n6   std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&)\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\n9   std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred()\n10  paddle::platform::DeviceContextPool::Get(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\n11  paddle::framework::GarbageCollector::GarbageCollector(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n12  paddle::framework::UnsafeFastGPUGarbageCollector::UnsafeFastGPUGarbageCollector(paddle::platform::CUDAPlace const&, unsigned long)\n13  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\n14  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\n\n----------------------\nError Message Summary:\n----------------------\nPaddleCheckError: Failed to find dynamic library: libcublas.so ( libcublas.so: cannot open shared object file: No such file or directory ) \n Please specify its path correctly using following ways: \n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \n For instance, issue command: export LD_LIBRARY_PATH=... \n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177]\n"
     ]
    }
   ],
   "source": [
    "# 设置训练设备\n",
    "use_cuda = True\n",
    "places = fluid.cuda_places() if use_cuda else fluid.cpu_places()\n",
    "# 设置数据源\n",
    "loader.set_batch_generator(inputs_generator(batch_size,\n",
    "                                            eos_id,\n",
    "                                            is_train=True),\n",
    "                            places=places)\n",
    "# 定义执行器，初始化参数并绑定Program\n",
    "exe = fluid.Executor(places[0])\n",
    "exe.run(startup_prog)\n",
    "prog = fluid.CompiledProgram(train_prog).with_data_parallel(\n",
    "    loss_name=loss.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\n2   paddle::platform::dynload::GetCublasDsoHandle()\n3   void std::__once_call_impl<std::_Bind_simple<paddle::platform::dynload::DynLoad__cublasCreate_v2::operator()<cublasContext**>(cublasContext**)::{lambda()#1} ()> >()\n4   paddle::platform::CublasHandleHolder::CublasHandleHolder(CUstream_st*, cublasMath_t)\n5   paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace)\n6   std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&)\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\n9   std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred()\n10  paddle::platform::DeviceContextPool::Get(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\n11  paddle::framework::GarbageCollector::GarbageCollector(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n12  paddle::framework::UnsafeFastGPUGarbageCollector::UnsafeFastGPUGarbageCollector(paddle::platform::CUDAPlace const&, unsigned long)\n13  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\n14  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\n\n----------------------\nError Message Summary:\n----------------------\nPaddleCheckError: Failed to find dynamic library: libcublas.so ( libcublas.so: cannot open shared object file: No such file or directory ) \n Please specify its path correctly using following ways: \n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \n For instance, issue command: export LD_LIBRARY_PATH=... \n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bd6625b97ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpass_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         print('pass_id: %d, batch_id: %d, loss: %f' %\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/reader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;34m\"Data source of DataLoader has not set yet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/reader.py\u001b[0m in \u001b[0;36m_init_iterable\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                                           self._capacity)\n\u001b[1;32m    349\u001b[0m         self._reader = core.create_py_reader(\n\u001b[0;32m--> 350\u001b[0;31m             self.queue, self._var_names, self._places, self._use_double_buffer)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_non_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<char const*>(char const*&&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::__exception_ptr::exception_ptr, char const*, int)\n2   paddle::platform::dynload::GetCublasDsoHandle()\n3   void std::__once_call_impl<std::_Bind_simple<paddle::platform::dynload::DynLoad__cublasCreate_v2::operator()<cublasContext**>(cublasContext**)::{lambda()#1} ()> >()\n4   paddle::platform::CublasHandleHolder::CublasHandleHolder(CUstream_st*, cublasMath_t)\n5   paddle::platform::CUDADeviceContext::CUDADeviceContext(paddle::platform::CUDAPlace)\n6   std::_Function_handler<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > (), std::reference_wrapper<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()> > >::_M_invoke(std::_Any_data const&)\n7   std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::__future_base::_Result_base::_Deleter>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > >::_M_invoke(std::_Any_data const&)\n8   std::__future_base::_State_base::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>&, bool&)\n9   std::__future_base::_Deferred_state<std::_Bind_simple<paddle::platform::EmplaceDeviceContext<paddle::platform::CUDADeviceContext, paddle::platform::CUDAPlace>(std::map<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >, std::less<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> >, std::allocator<std::pair<boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const, std::shared_future<std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > > > > >*, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>)::{lambda()#1} ()>, std::unique_ptr<paddle::platform::DeviceContext, std::default_delete<paddle::platform::DeviceContext> > >::_M_run_deferred()\n10  paddle::platform::DeviceContextPool::Get(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&)\n11  paddle::framework::GarbageCollector::GarbageCollector(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n12  paddle::framework::UnsafeFastGPUGarbageCollector::UnsafeFastGPUGarbageCollector(paddle::platform::CUDAPlace const&, unsigned long)\n13  paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool)\n14  paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, std::vector<std::string, std::allocator<std::string> > const&, bool)\n\n----------------------\nError Message Summary:\n----------------------\nPaddleCheckError: Failed to find dynamic library: libcublas.so ( libcublas.so: cannot open shared object file: No such file or directory ) \n Please specify its path correctly using following ways: \n Method. set environment variable LD_LIBRARY_PATH on Linux or DYLD_LIBRARY_PATH on Mac OS. \n For instance, issue command: export LD_LIBRARY_PATH=... \n Note: After Mac OS 10.11, using the DYLD_LIBRARY_PATH is impossible unless System Integrity Protection (SIP) is disabled. at [/paddle/paddle/fluid/platform/dynload/dynamic_loader.cc:177]\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 2\n",
    "for pass_id in six.moves.xrange(EPOCH_NUM):\n",
    "    batch_id = 0\n",
    "    for data in loader():\n",
    "        loss_val = exe.run(prog, feed=data, fetch_list=[loss])[0]\n",
    "        print('pass_id: %d, batch_id: %d, loss: %f' %\n",
    "                (pass_id, batch_id, loss_val))\n",
    "        batch_id += 1\n",
    "    # 保存模型\n",
    "    fluid.io.save_params(exe, model_save_dir, main_program=train_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data Type mismatch: 2 to 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-83ddd01b36da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m output, state = fluid.layers.rnn(cell=gru, \n\u001b[0;32m----> 3\u001b[0;31m                                         inputs=example_input_batch)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/layers/rnn.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(cell, inputs, initial_states, sequence_length, time_major, is_reverse, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mcopy_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/layers/rnn.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \"\"\"\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mnew_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mparallel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/contrib/layers/rnn_impl.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, pre_hidden)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mconcat_input_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hidden\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mgate_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_input_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gate_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/layers/tensor.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_variable_for_type_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     helper.append_op(\n\u001b[1;32m    297\u001b[0m         type='concat', inputs=inputs, outputs={'Out': [out]}, attrs=attrs)\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/layer_helper.py\u001b[0m in \u001b[0;36minput_dtype\u001b[0;34m(self, input_param_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0meach\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 raise ValueError(\"Data Type mismatch: %d to %d\" %\n\u001b[0;32m---> 98\u001b[0;31m                                  (dtype, each.dtype))\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data Type mismatch: 2 to 5"
     ]
    }
   ],
   "source": [
    "gru = fluid.layers.GRUCell(hidden_size=256)\n",
    "output, state = fluid.layers.rnn(cell=gru, \n",
    "                                        inputs=example_input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.fluid.layers.rnn.GRUCell object at 0x7febd40fbd90>\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(\"Encoder\", vocab_size, embedding_dim, embedding_matrix, units, BATCH_SIZE)\n",
    "# example_input\n",
    "example_input_batch = fluid.layers.ones(shape=(BATCH_SIZE,max_length_inp), dtype=\"int32\")\n",
    "# sample input\n",
    "#sample_hidden = encoder.initialize_hidden_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hidden\n",
    "import pdb; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8130d245d965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_input_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Encoder output shape: (batch size, sequence length, units) {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Encoder Hidden state shape: (batch size, units) {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mparallel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munpacked\u001b[0m \u001b[0mdict\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample_output, sample_hidden = encoder(example_input_batch)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_gpu=True\n",
    "print \"with gpu: \", with_gpu\n",
    "\n",
    "def save_model(trainer, save_path):\n",
    "    with open(save_path, 'w') as f:\n",
    "        trainer.save_parameter_to_tar(f)\n",
    "\n",
    "def load_word2vec_file(word2vec_file):\n",
    "    word2vec_dict = {}\n",
    "    input = codecs.open(word2vec_file, \"r\", \"utf-8\")\n",
    "    lines = input.readlines()\n",
    "    input.close()\n",
    "    word_num, dim = lines[0].split(\" \")\n",
    "    word_num = int(word_num)\n",
    "    dim = int(dim)\n",
    "    \n",
    "    lines = lines[1:]\n",
    "    for l in lines:\n",
    "        l = l.strip()\n",
    "        tokens = l.split(\" \")\n",
    "        if len(tokens) != dim + 1:\n",
    "            continue\n",
    "        w = tokens[0]\n",
    "        v = np.array(map(lambda x:float(x), tokens[1:]))\n",
    "        word2vec_dict[w] = v\n",
    "    return word2vec_dict, dim\n",
    "\n",
    "\n",
    "def seq_to_seq_net(vocab_size,\n",
    "                   is_generating,\n",
    "                   word_vector_dim=100,\n",
    "                   hidden_size=100,\n",
    "                   beam_size=3,\n",
    "                   max_length=100,\n",
    "                   dropout_rate=0.):\n",
    "\n",
    "    # Network Architecture\n",
    "    decoder_size = hidden_size  # dimension of hidden unit of GRU decoder\n",
    "    encoder_size = hidden_size  # dimension of hidden unit of GRU encoder\n",
    "\n",
    "    embedding_param = paddle.attr.ParamAttr(name='embedding')\n",
    "\n",
    "    def embedding_layer(word_id):\n",
    "        embed = paddle.layer.embedding(\n",
    "            input=word_id, size=word_vector_dim, param_attr=embedding_param)\n",
    "        return paddle.layer.dropout(input=embed, dropout_rate=dropout_rate)\n",
    "\n",
    "\n",
    "    def BiGru_layer(embedding):\n",
    "        forward = paddle.networks.simple_gru2(\n",
    "            input=embedding, size=encoder_size, \n",
    "            gru_param_attr=paddle.attr.ParamAttr(name='gru_forward_encoder'),\n",
    "            #gru_bias_attr=False,\n",
    "            #mixed_bias_attr=False,\n",
    "            mixed_param_attr=paddle.attr.ParamAttr(name='mixed_forward_encoder'))\n",
    "            \n",
    "        backward = paddle.networks.simple_gru2(\n",
    "            input=embedding, size=encoder_size, reverse=True,\n",
    "            gru_param_attr=paddle.attr.ParamAttr(name='gru_backward_encoder'),\n",
    "            #gru_bias_attr=False,\n",
    "            #mixed_bias_attr=False,\n",
    "            mixed_param_attr=paddle.attr.ParamAttr(name='mixed_backward_encoder'))\n",
    "        return forward, backward\n",
    "\n",
    "\n",
    "    #### Encoder\n",
    "    ##### Encode problem to a fixed size vector\n",
    "    problem_word_id = paddle.layer.data(\n",
    "        name='problem_word',\n",
    "        type=paddle.data_type.integer_value_sequence(vocab_size))\n",
    "\n",
    "    problem_embedding = embedding_layer(problem_word_id)\n",
    "\n",
    "    problem_f, problem_b = BiGru_layer(problem_embedding)\n",
    "    problem_f_last = paddle.layer.last_seq(input=problem_f)\n",
    "    problem_b_first = paddle.layer.first_seq(input=problem_b)\n",
    "\n",
    "    problem_vector = paddle.layer.concat(input=[problem_f_last, problem_b_first])\n",
    "    problem_vector = paddle.layer.dropout(input=problem_vector, dropout_rate=dropout_rate)\n",
    "\n",
    "    ##### Encode conversation\n",
    "    conversation_word_id = paddle.layer.data(\n",
    "        name='conversation_word',\n",
    "        type=paddle.data_type.integer_value_sequence(vocab_size))\n",
    "\n",
    "    conversation_embedding = embedding_layer(conversation_word_id)\n",
    "    conversation_f, conversation_b = BiGru_layer(conversation_embedding)\n",
    "    conversation_vector = paddle.layer.concat(input=[conversation_f, conversation_b])\n",
    "\n",
    "    #### Decoder\n",
    "    conversation_proj = paddle.layer.fc(\n",
    "        act=paddle.activation.Linear(),\n",
    "        size=decoder_size,\n",
    "        bias_attr=False,\n",
    "        input=conversation_vector)\n",
    "\n",
    "    backward_first = paddle.layer.first_seq(input=conversation_b)\n",
    "\n",
    "    decoder_boot = paddle.layer.fc(\n",
    "        size=decoder_size,\n",
    "        act=paddle.activation.Tanh(),\n",
    "        bias_attr=False,\n",
    "        input=backward_first)\n",
    "\n",
    "    def gru_decoder_with_attention(\n",
    "            enc_vec, enc_proj, problem_vec, current_word):\n",
    "\n",
    "        decoder_mem = paddle.layer.memory(\n",
    "            name='gru_decoder', size=decoder_size, boot_layer=decoder_boot)\n",
    "\n",
    "        context = paddle.networks.simple_attention(\n",
    "            encoded_sequence=enc_vec,\n",
    "            encoded_proj=enc_proj,\n",
    "            decoder_state=decoder_mem)\n",
    "\n",
    "        decoder_inputs = paddle.layer.fc(\n",
    "            act=paddle.activation.Linear(),\n",
    "            size=decoder_size * 3,\n",
    "            bias_attr=False,\n",
    "            input=[context, problem_vec, current_word],\n",
    "            layer_attr=paddle.attr.ExtraLayerAttribute(\n",
    "                error_clipping_threshold=100.0))\n",
    "\n",
    "        gru_step = paddle.layer.gru_step(\n",
    "            name='gru_decoder',\n",
    "            input=decoder_inputs,\n",
    "            output_mem=decoder_mem,\n",
    "            size=decoder_size)\n",
    "        \n",
    "        out = paddle.layer.mixed(size=vocab_size,\n",
    "            act=paddle.activation.Softmax(),\n",
    "            bias_attr=False,\n",
    "            ## 这里使用 embedding 矩阵参数 产生 report 的词\n",
    "            input=paddle.layer.trans_full_matrix_projection(\n",
    "                        input=gru_step,\n",
    "                        param_attr=embedding_param))\n",
    "        \n",
    "        return out\n",
    "\n",
    "    decoder_group_name = 'decoder_group'\n",
    "    group_input1 = paddle.layer.StaticInput(input=conversation_vector)\n",
    "    group_input2 = paddle.layer.StaticInput(input=conversation_proj)\n",
    "    group_input3 = paddle.layer.StaticInput(input=problem_vector)\n",
    "    group_inputs = [group_input1, group_input2, group_input3]\n",
    "\n",
    "    if not is_generating:\n",
    "        report_embedding = embedding_layer(paddle.layer.data(\n",
    "            name='report_word',\n",
    "            type=paddle.data_type.integer_value_sequence(vocab_size)))\n",
    "\n",
    "        group_inputs.append(report_embedding)\n",
    "\n",
    "        decoder = paddle.layer.recurrent_group(\n",
    "            name=decoder_group_name,\n",
    "            step=gru_decoder_with_attention,\n",
    "            input=group_inputs)\n",
    "\n",
    "        lbl = paddle.layer.data(\n",
    "            name='report_next_word',\n",
    "            type=paddle.data_type.integer_value_sequence(vocab_size))\n",
    "        cost = paddle.layer.classification_cost(input=decoder, label=lbl)\n",
    "\n",
    "        return cost\n",
    "    else:\n",
    "        report_embedding = paddle.layer.GeneratedInput(\n",
    "            size=vocab_size,\n",
    "            embedding_name='embedding',\n",
    "            embedding_size=word_vector_dim)\n",
    "        group_inputs.append(report_embedding)\n",
    "\n",
    "        beam_gen = paddle.layer.beam_search(\n",
    "            name=decoder_group_name,\n",
    "            step=gru_decoder_with_attention,\n",
    "            input=group_inputs,\n",
    "            bos_id=0,\n",
    "            eos_id=1,\n",
    "            beam_size=beam_size,\n",
    "            max_length=max_length)\n",
    "\n",
    "        return beam_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 2 required positional arguments: 'var' and 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c454f91bc08d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix_pa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 2 required positional arguments: 'var' and 'block'"
     ]
    }
   ],
   "source": [
    "embedding_matrix_pa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_pa = paddle.fluid.initializer.NumpyArrayInitializer(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_param_attrs = fluid.ParamAttr(name=\"fc_weight\",\n",
    "                                trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The type of 'input' in fc must be Variable, but received <class 'paddle.fluid.initializer.NumpyArrayInitializer'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fe7a27293381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_matrix_pa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_param_attrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/layers/nn.py\u001b[0m in \u001b[0;36mfc\u001b[0;34m(input, size, num_flatten_dims, param_attr, bias_attr, act, name)\u001b[0m\n\u001b[1;32m    356\u001b[0m             raise TypeError(\n\u001b[1;32m    357\u001b[0m                 \u001b[0;34m\"The type of 'input' in fc must be Variable, but received %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 (type(input)))\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The type of 'input' in fc must be Variable, but received <class 'paddle.fluid.initializer.NumpyArrayInitializer'>"
     ]
    }
   ],
   "source": [
    "y_predict = fluid.layers.fc(input=embedding_matrix_pa, size=10, param_attr=w_param_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33064, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fluid.layers.data(name='X', shape=embedding_matrix.shape, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3d097d1cdaf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix_pa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "embedding_matrix_pa(x, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fluid.layers.data(name=\"x\", shape=[33064], dtype='float32')\n",
    "fc = fluid.layers.fc(input=x, size=6612800,\n",
    "    param_attr=fluid.initializer.NumpyArrayInitializer(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_param_attrs = fluid.ParamAttr(\n",
    "    name=\"emb_weight\",\n",
    "    initializer=fluid.initializer.NumpyArrayInitializer(embedding_matrix),\n",
    "    trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = fluid.dygraph.Embedding(\n",
    "        name_scope='embedding',\n",
    "        size=[33064, 200],\n",
    "        param_attr= w_param_attrs,\n",
    "        is_sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inp_word = np.array([[[1]]]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "We Only support to_variable in Dygraph mode, please use fluid.dygraph.guard() as context to run it in Dygraph Mode",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0acf19946a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdygraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m</home/abner/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/decorator.py:decorator-gen-149>\u001b[0m in \u001b[0;36mto_variable\u001b[0;34m(value, block, name)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLP_Pro_01/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         assert in_dygraph_mode(\n\u001b[0;32m--> 206\u001b[0;31m         ), \"We Only support %s in Dygraph mode, please use fluid.dygraph.guard() as context to run it in Dygraph Mode\" % func.__name__\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: We Only support to_variable in Dygraph mode, please use fluid.dygraph.guard() as context to run it in Dygraph Mode"
     ]
    }
   ],
   "source": [
    "import paddle.fluid.dygraph.base as base\n",
    "emb(base.to_variable(inp_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_Pro_01",
   "language": "python",
   "name": "nlp_pro_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
